version: '2.1'

services:
    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        volumes:
            - /tmp/postgres-data:/var/lib/postgresql/data

    pgweb:
        container_name: pgweb
        restart: always
        image: sosedoff/pgweb
        ports: 
            - "3000:3000" 
        links: 
            - postgres:postgres  # my database container is called postgres, not db
        environment:
            - DATABASE_URL=postgres://airflow:airflow@postgres:5432/airflow?sslmode=disable
        depends_on:
            - postgres

    webserver:
        build: .
        restart: always
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
        volumes:
            - ./dags:/usr/local/airflow/dags
            - /tmp/airflow_logs:/root/airflow/logs
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    scheduler:
        build: .
        restart: always
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
        volumes:
            - ./dags:/usr/local/airflow/dags
            - /tmp/airflow_logs:/root/airflow/logs
        command: scheduler

    hadoop:
        container_name: hadoop
        build:
            context: ./hadoop
        restart: always
        ports:
            - "8088:8088"
            - "50070:50070"
            - "50075:50075"
        volumes:
            - ./sample:/var/log/sample
            - ./configs/hosts:/etc/hosts
            # - hadoop-node:/root/hdfs/
        networks:
            hadoop:
                ipv4_address: 172.28.1.10

    jupyterlab:
        container_name: jupyterlab
        build:
            context: ./jupiter
        ports:
            - 8888:8888
        volumes: 
            - ./scripts:/opt/workspace
        networks: 
            - hadoop
    
    spark-master:
        build:
            context: ./spark/master
        container_name: spark-master
        ports:
            - 7077:7077
        networks: 
            - hadoop
    
    spark-worker-1:
        build:
            context: ./spark/worker
        container_name: spark-worker-1
        environment:
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=512m
        ports:
            - 8081:8081
        depends_on:
            - spark-master
        networks: 
            - hadoop
